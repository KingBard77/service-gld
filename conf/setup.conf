# setup.conf

### PACKAGE
PACKAGE="curl wget vim tree net-tools qemu-guest-agent git nmap"
SSH_KEY="ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIHEcQ2TvyG2WjgBVy81jFFzmmbmvEeQfcu0Aqpm2Yg13 infra.admin@myid.my"

### NFS
NFS_SERVER="did-prms-svcd-afs-01"

### LOG
# ==== Elastic / Kibana ====
ES_VERSION="8.x"
#ES_HOST="10.211.55.107"
ES_HOST="did-prms-svcd-log-01"
ES_PORT="9200"
ES_USER="infra"
ES_PASS="infra#mydid123"

# ==== Certificates ====
CA_PATH="/etc/logstash/certs/http_ca.crt"     # will be created/filled by script

# ==== Logstash / Filebeat ====
LS_LISTEN_HOST="0.0.0.0"
LS_LISTEN_PORT="5044"

# ==== Index names ====
IDX_SYSLOG="syslog-%{+YYYY.MM.dd}"
IDX_AUTH="authlog-%{+YYYY.MM.dd}"
IDX_KERN="kernlog-%{+YYYY.MM.dd}"
IDX_DMESG="dmesglog-%{+YYYY.MM.dd}"

# Enable Logstash config auto-reload (optional)
LS_AUTORELOAD=true

# --------------------------------------------------------------------
#  Logstash conf snippets (expanded here in the conf, written by script)
# --------------------------------------------------------------------

LS_INPUT_CONF=$(cat <<EOF
input {
  beats {
    host => "${LS_LISTEN_HOST}"
    port => ${LS_LISTEN_PORT}
  }
}
EOF
)

LS_FILTER_CONF=$(cat <<'EOF'
filter {
  if [type] == "syslog" {
    grok {
      match => { "message" => "%{SYSLOGLINE}" }
      tag_on_failure => ["_grokparsefailure_syslog"]
    }
    date {
      match  => [ "timestamp", "MMM  d HH:mm:ss", "MMM dd HH:mm:ss" ]
      target => "@timestamp"
      tag_on_failure => ["_dateparsefailure"]
    }
  }
}
EOF
)

# NOTE: backslashes in regex already escaped
LS_OUTPUT_CONF=$(cat <<EOF
output {
  # AUTH -> ${IDX_AUTH}
  if [stream] == "auth"
     or [log][file][path] =~ "/auth(\\.log)?$"
     or [event][dataset] =~ /^system\\.auth/ {

    elasticsearch {
      hosts => ["https://${ES_HOST}:${ES_PORT}"]
      user  => "${ES_USER}"
      password => "${ES_PASS}"
      ssl_enabled                 => true
      ssl_certificate_authorities => ["${CA_PATH}"]
      ssl_verification_mode       => "full"
      index => "${IDX_AUTH}"
    }

  # KERN -> ${IDX_KERN}
  } else if [stream] == "kern"
     or [log][file][path] =~ "/kern(\\.log)?$"
     or [event][dataset] =~ /^system\\.kern/ {

    elasticsearch {
      hosts => ["https://${ES_HOST}:${ES_PORT}"]
      user  => "${ES_USER}"
      password => "${ES_PASS}"
      ssl_enabled                 => true
      ssl_certificate_authorities => ["${CA_PATH}"]
      ssl_verification_mode       => "full"
      index => "${IDX_KERN}"
    }

  # DMESG -> ${IDX_DMESG}
  } else if [stream] == "dmesg"
     or [log][file][path] =~ "/dmesg(\\.log)?$"
     or [event][dataset] =~ /^system\\.dmesg/ {

    elasticsearch {
      hosts => ["https://${ES_HOST}:${ES_PORT}"]
      user  => "${ES_USER}"
      password => "${ES_PASS}"
      ssl_enabled                 => true
      ssl_certificate_authorities => ["${CA_PATH}"]
      ssl_verification_mode       => "full"
      index => "${IDX_DMESG}"
    }

  # DEFAULT -> ${IDX_SYSLOG}
  } else {
    elasticsearch {
      hosts => ["https://${ES_HOST}:${ES_PORT}"]
      user  => "${ES_USER}"
      password => "${ES_PASS}"
      ssl_enabled                 => true
      ssl_certificate_authorities => ["${CA_PATH}"]
      ssl_verification_mode       => "full"
      index => "${IDX_SYSLOG}"
    }
  }

  stdout { codec => rubydebug }
}
EOF
)

# --------------------------------------------------------------------
#  Filebeat config (expanded here in the conf, written by script)
# --------------------------------------------------------------------
FB_YML=$(cat <<EOF
filebeat.inputs:
  - type: log
    enabled: true
    paths: ["/var/log/auth.log"]
    fields: { stream: auth }
    fields_under_root: true

  - type: log
    enabled: true
    paths: ["/var/log/syslog"]
    fields: { stream: syslog }
    fields_under_root: true

  - type: log
    enabled: true
    paths: ["/var/log/kern.log"]
    fields: { stream: kern }
    fields_under_root: true

  - type: log
    enabled: true
    paths: ["/var/log/dmesg.log"]
    fields: { stream: dmesg }
    fields_under_root: true

processors:
  - add_host_metadata: ~

output.logstash:
  hosts: ["127.0.0.1:${LS_LISTEN_PORT}"]
EOF
)


### MIL (MAIL)
POSTFIX_MAIN_CF="/etc/postfix/main.cf"
RELAYHOST="[sauron.mimos.my]:25"

### CMK (CHECKMK)
CMK_USER="infra"
CMK_PASSWORD="infra#mydid123"
CMK_AGENT_URL="http://172.16.64.14:5000/did_prms/check_mk/agents/"

### DHCP (DCP)
INTERFACE="ens18"
VM_IP="10.20.31.13/24" 
DNS_IP="8.8.8.8"
DCP_DOMAIN="mimos.local"
DCP_GATEWAY="10.20.31.254"

NETPLAN_DYNAMIC_CONTENT=$(cat <<EOL
network:
  version: 2
  renderer: networkd
  ethernets:
    $INTERFACE:
      dhcp4: yes
      nameservers:
        addresses:
          - $DNS_IP
EOL
)
NETPLAN_STATIC_CONTENT=$(cat <<EOL
network:
  version: 2
  renderer: networkd
  ethernets:
    $INTERFACE:
      addresses:
        - $VM_IP
      nameservers:
        addresses:
          - $DNS_IP
        search:
          - $DCP_DOMAIN
      routes:
        - to: default
          via: $DCP_GATEWAY
EOL
)

### LDAP (LDP)
LDP_DOMAIN="my"
LDP_PASSWORD="infra#mydid123"
LDP_SERVER="172.16.64.16"
#LDP_SERVER="did-prms-svcd-ldp-01"
LDP_ADMIN="admin"
LDP_NAME="digital-id"

CONF_ETC_NSLCD=$(cat <<EOF
uid nslcd
gid nslcd
uri ldap://$LDP_SERVER
base dc=$LDP_NAME,dc=$LDP_DOMAIN
ldap_version 3
binddn cn=$LDP_ADMIN,dc=$LDP_NAME,dc=$LDP_DOMAIN
rootpwmoddn cn=admin,dc=digital-id,dc=my
bindpw /etc/ldap.secret
tls_cacertfile /etc/ssl/certs/ca-certificates.crt
scope sub
EOF
)

### NETBOX (IPM)
NETBOX_URL="http://10.249.19.42"
NETBOX_TOKEN="4e5831d0d5323e636f291b719374eebfdefb7eaf"
NETBOX_PATH="/etc/netbox-agent/config.yaml"
NETBOX_AGENT_BIN="/opt/netbox-agent-venv/bin/netbox_agent"
CLUSTER_NAME="tmc-prmp-oobp"